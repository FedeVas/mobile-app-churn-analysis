## Результаты моделирования оттока и выбор стратегии порога

### 1) Базовые модели и качество
Мы построили модель прогнозирования оттока `churn_30d` на основе пользовательских агрегированных признаков (частота использования, сессии, активные дни, разнообразие экранов/функционала, параметры устройства).

Сравнили несколько моделей:
- **Logistic Regression (baseline)**: ROC-AUC ≈ 0.70  
- **RandomForest**: ROC-AUC ≈ 0.706  
- **CatBoost**: ROC-AUC ≈ 0.711  

Лёгкий тюнинг CatBoost (RandomizedSearch) существенного прироста не дал, что указывает на ограничение сигнала текущим набором признаков: дальнейший рост качества вероятнее достигается через улучшение фич/постановки, а не “перебором” параметров.

---

### 2) Почему AUC почти не меняется при порогах
ROC-AUC оценивает **качество ранжирования вероятностей**, и **не зависит от конкретного порога**, по которому мы переводим вероятность в класс (0/1).  
Зато при смене порога сильно меняются **precision / recall / F1**, что важно для практического выделения “группы риска”.

---

### 3) Сегментный анализ качества (по поведенческим кластерам)
Мы проверили, как качество модели различается по поведенческим кластерам пользователей. Результат показал **неоднородность**:
- в “high-churn” сегментах модель чаще относит пользователей к оттоку (высокий recall), но ранжирование внутри сегмента слабее;
- в “low-churn” сегментах AUC может быть нормальным, но при пороге 0.5 модель почти никого не относит к оттоку (низкий recall).

Это подтверждает, что единый порог 0.5 не оптимален: разные сегменты требуют разной “чувствительности”.

---

### 4) Эксперимент: исключение “проблемного” кластера
Мы проверили гипотезу, что один из кластеров ухудшает качество.  
После исключения выбранного кластера метрика выросла незначительно (ROC-AUC ≈ **0.717**), что подтверждает: основной ограничитель качества — **не один сегмент**, а общий уровень сигнала в признаках.

---

### 5) Сравнение стратегий выбора порога (финальный вывод)
Мы сравнили несколько политик перевода вероятности в класс:

1) **Глобальный порог 0.5** — baseline  
2) **Глобальный порог, оптимизирующий F1 на валидации** (≈ 0.37)  
3) **Сегментные пороги по кластерам** (подбор на валидации)  
4) **Сегментные пороги по (кластер + одноразовость)** — усложнённый routing

Результат:
- **Лучшую F1 на тесте показал глобальный порог best-F1 (≈ 0.37)**: улучшился баланс precision/recall.
- Сегментные пороги по кластерам повышают recall, но ухудшают precision и accuracy, поэтому F1 получается ниже глобального best-F1.
- Разбиение на (кластер + one_time) оказалось слишком “тонким”: сегменты становятся малыми и пороги нестабильными, итоговый F1 ниже baseline.

**Итог:** в качестве финального решения мы используем **CatBoost + глобальный порог best-F1**, а сегментный анализ по кластерам применяем для интерпретации и продуктовых рекомендаций.

---

### 6) Что можно улучшить в следующей итерации
- Добавить более “временные” признаки: динамика активности (последние 7/14/30 дней до cutoff), тренды, спады.
- Модели последовательностей действий (LSTM/Transformer) по цепочкам экранов/действий.
- NLP-анализ отзывов/обращений для выявления причин оттока и болей пользователей.
